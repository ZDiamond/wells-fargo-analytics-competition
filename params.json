{"name":"Wells Fargo Social Media Analytics Competition","tagline":"Zach Diamond","body":"#Wells Fargo Analytics Competition\r\n##Zach Diamond\r\n###Dr. Anderson's Data 101\r\n\r\n\r\n\r\n##Introduction\r\n\r\nWells Fargo assigned an analytics competition in which participants analyzed Twitter and Facebook data to deduce novel information on the customer service of 4 different bank branches. This competition provided me with real-world experience as to manipulate public data to create business insights. \r\n\r\n##Methodology \r\n\r\nWe decided that the best way to manipulate the data from social media posts was to organize them by sentiment scores. To calculate a sentiment score, we created lists of positive and negative words, then found which posts contained which words. Posts that were given sentiments scored >=2 or <=2 defined as being very positive or very negative, respectively. Out of the entire dataset, we sampled a data frame of 10000 posts to determine sentiment scores for each social medium. I then used this same data frame to create sentiment scores for each bank so that customer service can be compared across individual banks. From this data frame, we created 5 word clouds, one for each bank, and one for the combination of all the banks.\r\n\r\nBefore cleaning, data looked at follows:\r\n\r\n![](http://i.imgur.com/BLop2Jk.png)\r\n\r\n`To preprocess data we used code:`\r\n\r\n`df = read.table('dataset.txt',sep=\"|\",header=T)`\r\n`df$FullText = as.character(df$FullText)`\r\n\r\n`df.texts.clean = as.data.frame(iconv(df$FullText, \"latin1\", \"ASCII\", sub=\"\"))`\r\n`colnames(df.texts.clean) = 'FullText'`\r\n\r\n`df$FullText = df.texts.clean$FullText`\r\n\r\n`idx.10000 = sample(1:nrow(df),10000)`\r\n`df.10000 = df[idx.10000,]`\r\n\r\n`df.entire = df`\r\n`df = df.10000`\r\n\r\n`library(tm) `\r\n`docs <- Corpus(DataframeSource(as.data.frame(df[,6])))   `\r\n\r\n`library(rJava)`\r\n`docs <- tm_map(docs, content_transformer(tolower)) # convert to lowercase first`\r\n`docs <- tm_map(docs, removeWords, stopwords('english'))`\r\n`docs <- tm_map(docs, removeWords, stopwords(kind = \"SMART\"))`\r\n\r\n`myMeta <- c(\"name\",\"bank\",\"banka\",\"bankb\",\"bankc\", \"bankd\", \"banke\",`\r\n            `\"internet\",\"https\", \"rettwit\", \"twithndl\", \"twit_hndl_banka\",`\r\n            `\"twit_hndl_bankb\",\"twit_hndl_bankc\",\"twit_hndl_bankd\", \"phone\",`\r\n            `\"dirmsg\", \"street\",\"name_resp\",\"bankds\", \"and\", \"for\", \"the\", \"you\",`\r\n            `\"twithndlbanka\",\"dir_msg\",\"ret_twit\",\"twit_hndl\")`\r\n`docs <- tm_map(docs, removeWords, myMeta)`\r\n`docs <- tm_map(docs, stripWhitespace)`\r\n`docs <- tm_map(docs, removePunctuation)`\r\n`docs <- tm_map(docs, PlainTextDocument)`\r\n\r\n`dtm <- DocumentTermMatrix(bankA.docs)`\r\n`dtm = removeSparseTerms(dtm, 0.98)`\r\n\r\n`new.df <-data.frame(text=unlist(sapply(dtm, `[`, \"content\")), stringsAsFactors=F) `\r\n\r\n`For sentiment analysis we uploaded a database listing positive and negative words and then used code:`\r\n`pos <- scan('positive-words.txt',what='character',comment.char=';')`\r\n`neg <- scan('negative-words.txt',what='character',comment.char=';')`\r\n\r\n`score.sentiment = function(sentences, pos.words, neg.words, .progress='none')`\r\n`{`\r\n  `require(plyr)`\r\n  `require(stringr)`\r\n  `scores = laply(sentences, function(sentence, pos.words, neg.words) {`\r\n    \r\n    `sentence = gsub('[[:punct:]]', '', sentence)`\r\n    `sentence = gsub('[[:cntrl:]]', '', sentence)`\r\n    `sentence = gsub('\\\\d+', '', sentence)`\r\n    `sentence = tolower(sentence)`\r\n    \r\n    `word.list = str_split(sentence, '\\\\s+')`\r\n    `words = unlist(word.list)`\r\n    \r\n    `pos.matches = match(words, pos.words)`\r\n    `neg.matches = match(words, neg.words)`\r\n    \r\n    `pos.matches = !is.na(pos.matches)`\r\n    `neg.matches = !is.na(neg.matches)`\r\n   \r\n    `score = sum(pos.matches) - sum(neg.matches)`\r\n    \r\n    `return(score)`\r\n  `}, pos.words, neg.words, .progress=.progress )`\r\n  \r\n  `scores.df = data.frame(score=scores, text=sentences)`\r\n  `return(scores.df)`\r\n`}`\r\n`scores$very.pos = as.numeric(scores$score >= 2)`\r\n`scores$very.neg = as.numeric(scores$score <= -2)`\r\n\r\n`To create word clusters, we used code: `\r\n`library(rJava)`\r\n`docs <- tm_map(docs, content_transformer(tolower))`\r\n`myMeta <- c(\"name\",\"bank\",\"banka\",\"bankb\",\"bankc\", \"bankd\", \"internet\",`\r\n             `\"https\", \"rettwit\", \"twithndl\", \"twithndlbanka\",\"twithndlbankb\",`\r\n             `\"twithndlbankc\",\"twithndlbankd\", \"phone\", \"dirmsg\", \"street\",`\r\n             `\"nameresp\",\"bankds\")`\r\n`docs <- tm_map(docs, removeWords, myMeta)`\r\n\r\n`myStopwords <- c(stopwords('english'))`\r\n`docs <- tm_map(docs, removeWords, myStopwords) # then take out english stopwords`\r\n\r\n \r\n`docs <- tm_map(docs, stripWhitespace)`\r\n`docs <- tm_map(docs, removePunctuation)`\r\n`docs <- tm_map(docs, PlainTextDocument)`\r\n\r\n\r\n\r\n`bankA.idx = which(sapply(df$FullText,function(x) grepl(\"BankA\",x)))`\r\n`bankB.idx = which(sapply(df$FullText,function(x) grepl(\"BankB\",x)))`\r\n`bankC.idx = which(sapply(df$FullText,function(x) grepl(\"BankC\",x)))`\r\n`bankD.idx = which(sapply(df$FullText,function(x) grepl(\"BankD\",x)))`\r\n\r\n`df$BankID = vector(mode=\"numeric\",length = nrow(df))`\r\n`df$BankID[bankA.idx] = \"BankA\"`\r\n`df$BankID[bankB.idx] = \"BankB\"`\r\n`df$BankID[bankC.idx] = \"BankC\"`\r\n`df$BankID[bankD.idx] = \"BankD\"`\r\n\r\n`bankA.docs = docs[bankA.idx]`\r\n`bankB.docs = docs[bankB.idx]`\r\n`bankC.docs = docs[bankC.idx]`\r\n`bankD.docs = docs[bankD.idx] `\r\n\r\n\r\n`dtm <- DocumentTermMatrix(bankA.docs)`\r\n`dtm = removeSparseTerms(dtm, 0.98)`\r\n`dtm`\r\n\r\n\r\n`findFreqTerms(dtm,2000)`\r\n\r\n`freq <- colSums(as.matrix(dtm))  `\r\n`freq`\r\n`ord <- order(freq)   `\r\n\r\n`library(wordcloud)`\r\n`wordcloud(names(freq), freq, colors=brewer.pal(8, \"Dark2\"))`\r\n\r\n##Data\r\n\r\n###Sentiment Analysis\r\n\r\nOur data shows that people are more likely to leave positive posts on Facebook rather than on Twitter. This conclusion could have further implications as to how banks market themselves on each social medium. Because Twitter is a live feed, customers may be more inclined to post a quick, negative review after a poor experience. On the other hand, Facebook acts as a static page on which reviews are not necessarily organized chronologically. After a positive experience, customers may find it more appealing to leave a positive review on a Facebook page. Another way of thinking about this is that positive reviews have no substantial, personal benefit. Bad reviews, in contrast, may function in getting a bank’s attention to inspire more help, discounts, or a change in customer service. When live Tweeting, bank may respond and help the individual having a poor experience.\r\n\r\nGlobal sentiment scores were calculated to be:\r\n\r\nAll Banks (df.1000): 59\r\nBank A: 57\r\nBank B: 56\r\nBank C: 74\r\nBank D: 50\r\n\r\nUsing the formula (global_score = round( 100 * numpos / (numpos + numneg)). \r\n\r\nAverage sentiment scores were determined using:\r\nY axis: average of score (= sum(pos.matches) - sum(neg.matches)) of each social media post in data frame (ex. df.bankA)\r\n\r\n![](http://i.imgur.com/9ADeiCy.png)\r\n\r\n\r\n###Word Clusters\r\n\r\nAll banks’ word cluster:\r\n\r\n![](http://i.imgur.com/sDbHWfp.png)\r\n\r\nBank A word cluster:\r\n\r\n![](http://i.imgur.com/KckF1iR.png)\r\n\r\nBanks B word cluster:\r\n\r\n![](http://i.imgur.com/Rf2cg2K.png)\r\n\r\nBank C word cluster:\r\n\r\n![](http://i.imgur.com/XK771DF.png)\r\n\r\nBank D word cluster:\r\n\r\n![](http://i.imgur.com/JdwacjO.png)\r\n\r\nFor a word to appear in the word cluster, it must have appeared at least 50 times in posts. Looking at these words clusters, we can deduce information about how customers feel about banks as a whole and how individual banks differ in customer service. Every bank, with the exception of Bank D, exhibited words “phone” and “call,” showing that customer service is a vital part of a bank’s overall reception. While one might assume that financial competence is the key proponent of a bank’s overall success, these word clusters stress that customer service is just as important. Providing poor service to customers or potential customers on the phone, could be extremely detrimental. While sacrificing the quality of employees who work phones may seem like a simple way to cut costs, banks should keep in mind that phone conversations are an integral part of customer service and it may be advantageous to spend more money on properly trained individuals. \r\nComparing bank word clusters, Bank D stood out from the rest, exhibiting word that actually involve finance. Bank D’s data was comprised of financial terms such as “financial management”, “grants”, and “advisers.” For some reason, Bank D inspires more specific topics. Looking at verbs, Bank D exhibited active verbs such as “swing,” “apply,” and “program.” Other banks showed less informative verbs such as “like” and “can.” Evidently, Bank D prompts more meticulous posts. Perhaps they have some sort of reward system for customer reviews, or merely encourage reviews after an issue has been resolved. Another possibility is that Bank D has no customer service issues; therefore, people only Tweet about their finances. Either way, other banks should look at Bank D’s procedure if they are in need of more informative social media reviews. Interestingly, Bank D had the lowest global sentiment score. This could be because the posts were less emotional and more direct.\r\nCombining sentiment scores with word clusters, we can look at word clusters for each bank for both positive sentiment scores and lower sentiment scores. This enables us to distinguish which words are being used after a positive experience and after a negative experience, thus being able to determine where the bank is excelling and where it needs improvement. Overall positive and negative word clusters for all the banks were as follows:\r\nPositive:\r\n\r\n![](http://i.imgur.com/TUqYkXf.png)\r\n\r\nNegative:\r\n\r\n![](http://i.imgur.com/y5vJML1.png)\r\n\r\nAsides from expletives, shared terms, and general positive words, we can distinguish what terms people use in different contexts. In positive posts, people use words “support,” “work,” and “business,” showing that completed transactions result in positive experiences. Negative posts, on the other hand, exhibit words “money,” “pay,” and “card.” People may post negatively when they are required to spend extra money or need to request/cancel cards.\r\n\r\n###Word clusters for Bank A:\r\nPositive:\r\n\r\n![](http://i.imgur.com/CPJG0F8.png)\r\n\r\nNegative:\r\n\r\n![](http://i.imgur.com/8x5xLIT.png)\r\n\r\nEvidently, Bank A has problems with customer service as its negative word cluster shows both “customer” and “service.” Showing words “scam” and “fraud,” Bank A clearly has issues gaining the trust of its customers.\r\n\r\n###Word clusters for Bank B:\r\nPositive:\r\n\r\n![](http://i.imgur.com/LLca83v.png)\r\n\r\nNegative:\r\n\r\n![](http://i.imgur.com/lbzq3mL.png)\r\n\r\nSimilar to Bank A, Bank B also showed “support” in the positive word cloud, and “card” in the negative. However, customer service was not included in the negative. Bank B most likely has organizational issues showing “people,” and “rebank,” rather than customer service issues.\r\n\r\n###Word clusters for Bank C:\r\nPositive:\r\n\r\n![](http://i.imgur.com/JPADsWg.png)\r\n\r\nNegative:\r\n\r\n![](http://i.imgur.com/Vj2gd5f.png)\r\n\r\nBank C has clear issues with their card services as “card” was the most common word. Additionally, Bank C has “time” in its negative word cluster. The speed of service may be an issue for this bank.\r\n\r\n###Word clusters for Bank D:\r\nPositive:\r\n\r\n![](http://i.imgur.com/iwMByli.png)\r\n\r\nNegative:\r\n\r\n![](http://i.imgur.com/oqEvCBf.png)\r\n\r\nSimilar to Bank B, Bank D does not have customer service issues. However, showing words like “money,” “card,” and “fraud,” Bank D may have trust and organizational issues.\r\n\r\nThis competition gave me experience in business consulting via data analysis. By manipulating words posted on Twitter and Facebook, I could come to conclusions for how the bank operates and where it needs improvement.\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}